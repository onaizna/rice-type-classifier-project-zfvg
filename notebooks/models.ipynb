{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e28947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676cfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"../data/raw/Rice_Cammeo_Osmancik.csv\")\n",
    "\n",
    "df['Class_encoded'] = df['Class'].map({'Cammeo': 0, 'Osmancik': 1})\n",
    "X = df.drop(columns=['Class', 'Class_encoded'])  # features\n",
    "y = df['Class_encoded']  # target\n",
    "\n",
    "# Train/test split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e16d9",
   "metadata": {},
   "source": [
    "# MODELS \n",
    "\n",
    "i modelli senza PCA \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec99cc1",
   "metadata": {},
   "source": [
    "### RANDOM FOREST \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0872b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9251968503937008\n",
      "Precision: 0.927710843373494\n",
      "Recall: 0.9344660194174758\n",
      "F1 Score: 0.9310761789600968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e8f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[len(results_df)] = ['RF', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe5123",
   "metadata": {},
   "source": [
    "### SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31201d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.931758530183727\n",
      "Precision: 0.9265402843601895\n",
      "Recall: 0.9490291262135923\n",
      "F1 Score: 0.9376498800959233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "svc = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train the SVM model\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c897cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[len(results_df)] = ['SVC', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f5d21",
   "metadata": {},
   "source": [
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d492296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9173228346456693\n",
      "Precision: 0.9204819277108434\n",
      "Recall: 0.9271844660194175\n",
      "F1 Score: 0.9238210399032648\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the pipeline with the preprocessor and an XGBoost classifier\n",
    "XGB = xgb.XGBClassifier( eval_metric='logloss')\n",
    "\n",
    "# Train the XGBoost model\n",
    "XGB.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = XGB.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0feb4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[len(results_df)] = ['XGB', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75caa5bf",
   "metadata": {},
   "source": [
    "# MODELLI CON PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa2c8d",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "prima faccio la pca e prendo le componenti importanti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd1343c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Componenti selezionate: 3\n"
     ]
    }
   ],
   "source": [
    "# Standardizzazione \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA sul dataset\n",
    "pca = PCA()\n",
    "X_pca_full = pca.fit_transform(X_scaled)\n",
    "\n",
    "#Seleziona il numero di componenti che spiegano il 95% varianza \n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components_95 = np.argmax(explained_variance >= 0.95) + 1\n",
    "print(f\"Componenti selezionate: {n_components_95}\")\n",
    "\n",
    "# tengo solo le componenti importanti\n",
    "pca_final = PCA(n_components=n_components_95)\n",
    "X_pca = pca_final.fit_transform(X_scaled)\n",
    "\n",
    "# Train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c695c84",
   "metadata": {},
   "source": [
    "### Random Forest con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf2ea8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9186351706036745\n",
      "Precision: 0.9206730769230769\n",
      "Recall: 0.9296116504854369\n",
      "F1 Score: 0.9251207729468599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4299416",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[len(results_df)] = ['RF_pca', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef936f3",
   "metadata": {},
   "source": [
    "### SVG con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6b990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9291338582677166\n",
      "Precision: 0.9365853658536586\n",
      "Recall: 0.9320388349514563\n",
      "F1 Score: 0.9343065693430657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "svc = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebf389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[len(results_df)] = ['SVC_pca', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1ec30",
   "metadata": {},
   "source": [
    "### XGBoosting con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e19e3399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9173228346456693\n",
      "Precision: 0.9266503667481663\n",
      "Recall: 0.9199029126213593\n",
      "F1 Score: 0.9232643118148599\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the pipeline with the preprocessor and an XGBoost classifier\n",
    "XGB = xgb.XGBClassifier( eval_metric='logloss')\n",
    "\n",
    "# Train the XGBoost model\n",
    "XGB.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = XGB.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0505b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[len(results_df)] = ['XGB_pca', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da4c6724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.934466</td>\n",
       "      <td>0.931076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.931759</td>\n",
       "      <td>0.926540</td>\n",
       "      <td>0.949029</td>\n",
       "      <td>0.937650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.917323</td>\n",
       "      <td>0.920482</td>\n",
       "      <td>0.927184</td>\n",
       "      <td>0.923821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_pca</td>\n",
       "      <td>0.918635</td>\n",
       "      <td>0.920673</td>\n",
       "      <td>0.929612</td>\n",
       "      <td>0.925121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC_pca</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.936585</td>\n",
       "      <td>0.932039</td>\n",
       "      <td>0.934307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB_pca</td>\n",
       "      <td>0.917323</td>\n",
       "      <td>0.926650</td>\n",
       "      <td>0.919903</td>\n",
       "      <td>0.923264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Accuracy  Precision    Recall  F1 Score\n",
       "0       RF  0.925197   0.927711  0.934466  0.931076\n",
       "1      SVC  0.931759   0.926540  0.949029  0.937650\n",
       "2      XGB  0.917323   0.920482  0.927184  0.923821\n",
       "3   RF_pca  0.918635   0.920673  0.929612  0.925121\n",
       "4  SVC_pca  0.929134   0.936585  0.932039  0.934307\n",
       "5  XGB_pca  0.917323   0.926650  0.919903  0.923264"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8921a59",
   "metadata": {},
   "source": [
    "### Naive Bayes con PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "457fcc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.926509186351706\n",
      "Precision: 0.9178403755868545\n",
      "Recall: 0.9490291262135923\n",
      "F1 Score: 0.9331742243436754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()  # Laplace smoothing\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996978b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[len(results_df)] = ['NB', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bc257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.934466</td>\n",
       "      <td>0.931076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.931759</td>\n",
       "      <td>0.926540</td>\n",
       "      <td>0.949029</td>\n",
       "      <td>0.937650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.917323</td>\n",
       "      <td>0.920482</td>\n",
       "      <td>0.927184</td>\n",
       "      <td>0.923821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_pca</td>\n",
       "      <td>0.918635</td>\n",
       "      <td>0.920673</td>\n",
       "      <td>0.929612</td>\n",
       "      <td>0.925121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC_pca</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.936585</td>\n",
       "      <td>0.932039</td>\n",
       "      <td>0.934307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB_pca</td>\n",
       "      <td>0.917323</td>\n",
       "      <td>0.926650</td>\n",
       "      <td>0.919903</td>\n",
       "      <td>0.923264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.926509</td>\n",
       "      <td>0.917840</td>\n",
       "      <td>0.949029</td>\n",
       "      <td>0.933174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Accuracy  Precision    Recall  F1 Score\n",
       "0       RF  0.925197   0.927711  0.934466  0.931076\n",
       "1      SVC  0.931759   0.926540  0.949029  0.937650\n",
       "2      XGB  0.917323   0.920482  0.927184  0.923821\n",
       "3   RF_pca  0.918635   0.920673  0.929612  0.925121\n",
       "4  SVC_pca  0.929134   0.936585  0.932039  0.934307\n",
       "5  XGB_pca  0.917323   0.926650  0.919903  0.923264\n",
       "6       NB  0.926509   0.917840  0.949029  0.933174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
